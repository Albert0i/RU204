
### Data 101 : The way to feed and misfeed a Redis database

"There is no cause without consequences."

「世上沒有無緣無故的愛；也沒有無緣無故的恨。」


### Prologue 
Sailing across the sea of sequels in solitude, a sense of fury and placidness surged within and without. For I was there, I have been crafting sequels for more than three decades. I have seen raging sea storms uproar several hundreds of miles, I have seen whirlpools embeddedly descended numerous fathoms down to hell. And now in my boat, it is both smooth and soothing as in my soul... 


### I. [RU101](https://github.com/redislabs-training/ru101)
#### 1. Using `dumpload.py` data loader 
Go ahead and load the data as follows:
```
$ git clone https://github.com/redislabs-training/ru101.git
$ cd ru101
$ export PYTHONPATH=`pwd`
$ python3 -m venv venv
$ . venv/bin/activate
$ pip install -r requirements.txt

$ export REDIS_HOST=myredishost
$ export REDIS_PORT=9999
$ export REDIS_PASSWORD=ssssh

$ cd redisu
$ python utils/dumpload.py load ru101/data/ru101.json
```

`dumpload.py` is a utility to dump and load keys from Redis. It dumps Redis Core datatypes, ie. `string`, `list`, `set`, `sorted set` and `hash` into a kind/line of JSON format which can then be restored back into system. I slightly modified the source code to suit my need. Usage: 
```
python dumpload.py dump <output.json> <prefix>

python dumpload.py load <input.json>
```

To test with: 
```
set test:string "Testing Testing"
rpush test:list a b c 1 2 3
sadd test:set A B C 1 2 3
hset test:hash field1 101 field2 "Boy" field3 True
zadd test:zset 1 A 2 B 3 C 4 D 5 E 6 F 
```

To dump with: 
```
python dumpload.py dump test.json test:*
```

test.json
```
{"t": "set", "k": "test:set", "ttl": -1, "v": ["1", "3", "2", "B", "A", "C"]}
{"t": "zset", "k": "test:zset", "ttl": -1, "v": [["A",  1.0], ["B",  2.0], ["C",  3.0], ["D",  4.0], ["E",  5.0], ["F",  6.0]]}
{"t": "string", "k": "test:string", "ttl": -1, "e": "embstr", "v": "Testing Testing"}
{"t": "hash", "k": "test:hash", "ttl": -1, "v": {"field1": "101", "field2": "Boy", "field3": "True"}}
{"t": "list", "k": "test:list", "ttl": -1, "v": ["a", "b", "c", "1", "2", "3"]}
```

Remove test data: 
```
del test:string 
del test:list 
del test:set
del test:hash 
del test:zset
```

To load with: 
```
python dumpload.py load test.json
```


#### 2. Replacing the data store in one go
In case your local server is [Redis 7.2.4](https://redis.io/docs/latest/operate/rs/release-notes/rs-7-2-4-releases/), download the `ru101.rdb` from: 
```
https://storage.googleapis.com/redis-university-assets/ru101/ru101.rdb.gz
```
The ".rdb" file is used by Redis to persistently store data on disk. It serves as a point-in-time snapshot of the Redis dataset. The data in Redis, which is primarily stored in memory, is periodically saved to disk in the ".rdb" format to provide durability and allow data recovery in case of system failures or restarts.

When Redis restarts, it can load the data from the ".rdb" file back into memory, restoring the database state to the point of the last snapshot. This process is known as RDB (Redis DataBase) loading.
(Generated by Chat-GPT)

Find out the location and name of your redis data store from [`redis.conf`](https://redis.io/docs/latest/operate/oss_and_stack/management/config-file/):

redis.conf
```
# Save the DB to disk.
#
# save <seconds> <changes> [<seconds> <changes> ...]
#
# Redis will save the DB if the given number of seconds elapsed and it
# surpassed the given number of write operations against the DB.
#
# Snapshotting can be completely disabled with a single empty string argument
# as in following example:
#
# save ""
#
# Unless specified otherwise, by default Redis will save the DB:
#   * After 3600 seconds (an hour) if at least 1 change was performed
#   * After 300 seconds (5 minutes) if at least 100 changes were performed
#   * After 60 seconds if at least 10000 changes were performed
#
# You can set these explicitly by uncommenting the following line.
#
# save 3600 1 300 100 60 10000

# By default Redis will stop accepting writes if RDB snapshots are enabled
# (at least one save point) and the latest background save failed.
# This will make the user aware (in a hard way) that data is not persisting
# on disk properly, otherwise chances are that no one will notice and some
# disaster will happen.
#
# If the background saving process will start working again Redis will
# automatically allow writes again.
#
# However if you have setup your proper monitoring of the Redis server
# and persistence, you may want to disable this feature so that Redis will
# continue to work as usual even if there are problems with disk,
# permissions, and so forth.
stop-writes-on-bgsave-error yes

# Compress string objects using LZF when dump .rdb databases?
# By default compression is enabled as it's almost always a win.
# If you want to save some CPU in the saving child set it to 'no' but
# the dataset will likely be bigger if you have compressible values or keys.
rdbcompression yes

# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.
# This makes the format more resistant to corruption but there is a performance
# hit to pay (around 10%) when saving and loading RDB files, so you can disable it
# for maximum performances.
#
# RDB files created with checksum disabled have a checksum of zero that will
# tell the loading code to skip the check.
rdbchecksum yes

# Enables or disables full sanitization checks for ziplist and listpack etc when
# loading an RDB or RESTORE payload. This reduces the chances of a assertion or
# crash later on while processing commands.
# Options:
#   no         - Never perform full sanitization
#   yes        - Always perform full sanitization
#   clients    - Perform full sanitization only for user connections.
#                Excludes: RDB files, RESTORE commands received from the master
#                connection, and client connections which have the
#                skip-sanitize-payload ACL flag.
# The default should be 'clients' but since it currently affects cluster
# resharding via MIGRATE, it is temporarily set to 'no' by default.
#
# sanitize-dump-payload no

# The filename where to dump the DB
dbfilename dump.rdb

# Remove RDB files used by replication in instances without persistence
# enabled. By default this option is disabled, however there are environments
# where for regulations or other security concerns, RDB files persisted on
# disk by masters in order to feed replicas, or stored on disk by replicas
# in order to load them for the initial synchronization, should be deleted
# ASAP. Note that this option ONLY WORKS in instances that have both AOF
# and RDB persistence disabled, otherwise is completely ignored.
#
# An alternative (and sometimes better) way to obtain the same effect is
# to use diskless replication on both master and replicas instances. However
# in the case of replicas, diskless is not always an option.
rdb-del-sync-files no

# The working directory.
#
# The DB will be written inside this directory, with the filename specified
# above using the 'dbfilename' configuration directive.
#
# The Append Only File will also be created inside this directory.
#
# Note that you must specify a directory here, not a file name.
dir ./
```
In the above settings, data store name is `dump.rdb` and located in the same folder of the `redis-server` program. 
Shut down your redis server, replace the *.rdb file and restart. 


### II. [RU102JS](https://github.com/redislabs-training/ru102js): Using python data loader 
To load sample site data and sample metrics, run:
```
npm run load src/resources/data/sites.json flushdb
```
`flushdb` is optional, and will erase ALL data from Redis before inserting the sample data.

package.json 
```
{
  . . .
    "load": "node src/utils/data_loader.js --",
  . . .
}
```

Oh! It's Javascript... I LOVE Javascript! 

redis_client.js
```
const redis = require('redis');
const bluebird = require('bluebird');
const config = require('better-config');

// Add extra definitions for RedisTimeSeries commands.
redis.addCommand('ts.add'); // redis.ts_addAsync
redis.addCommand('ts.range'); // redis.ts_rangeAsync

// Promisify all the functions exported by node_redis.
bluebird.promisifyAll(redis);

// Create a client and connect to Redis using configuration
// from config.json.
const clientConfig = {
  host: config.get('dataStores.redis.host'),
  port: config.get('dataStores.redis.port'),
};

if (config.get('dataStores.redis.password')) {
  clientConfig.password = config.get('dataStores.redis.password');
}

const client = redis.createClient(clientConfig);

// This is a catch all basic error handler.
client.on('error', error => console.log(error));

module.exports = {
  /**
   * Get the application's connected Redis client instance.
   *
   * @returns {Object} - a connected node_redis client instance.
   */
  getClient: () => client,
};
```


### III. [RU203](https://github.com/redislabs-training/ru203): Using Redis-Cli
To load this data, run the following command from your terminal: 
```
redis-cli < commands.redis > output.txt
```
This is the most natural and easy way, as every line is virtually a single Redis command. 


### IV. [RU204](https://github.com/redislabs-training/ru204): Using python data loader 
First, with your shell in the ru204 folder create a Python virtual environment, activate it and install the dependencies required to run the data loader:
```
python3 -m venv venv
. ./venv/bin/activate
pip install -r requirements.txt
```

Now run the data loader script, passing it the name of the folder containing the JSON data files to load into Redis.
```
python data_loader.py --dir data/books --redis redis://default:password@host:port/
```

`data_loader.py` is a customized utility to load scattered book JSON data within a folder, upon finished loading, further verification is done check the data. 


### V. Eraser 
delete-keys.lua
```
local cursor="0";
local count = 0;

if (not ARGV[1]) then 
    return "Usage: redis-cli --eval delete_keys.lua , my_prefix"
end 

local prefix = ARGV[1] .. '*'

repeat
 local scanResult = redis.call("SCAN", cursor, "MATCH", prefix, "COUNT", 100);
	local keys = scanResult[2];
	for i = 1, #keys do
		local key = keys[i];		
        redis.call("DEL", key);
		count = count +1;
	end;
	cursor = scanResult[1];
until cursor == "0";
return "Total "..count.." keys Deleted" ;
```
```
redis-cli --eval delete_keys.lua , my_prefix 
```

### Epilogue
I have enrolled four courses in [Redis University](https://redis.io/university/), each course has it's own way to setup and feed data into the lab environment. Even worse, loaders are written in [`python`](https://www.python.org/), a language I am completely unfamiliar with... I was almost dizzy and crazy about that... 


### EOF (2024/04/19)
